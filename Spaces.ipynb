{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djveBckFZ8uW",
        "outputId": "f6f93485-2643-4bcc-c409-9cf249cc769e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.12/dist-packages (2.0.4)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wxDmmxRU8ud",
        "outputId": "31666665-a89d-4955-f7f4-e656dab273ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "онсказал: 'Яволк 'родилсяв СССР\n",
            "Яродлсяв 2014, этопосле 2013 года.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def insert_spaces(text):\n",
        "    \"\"\"\n",
        "    Применяем набор правил, для формирования начального разбиения предложений\n",
        "    \"\"\"\n",
        "    new_text = \"\"\n",
        "    prev_char = \"\"\n",
        "\n",
        "    # Список сокращений, которые нельзя разрывать\n",
        "    abbreviations = [\"т.е.\", \"и т.д.\", \"г.\", \"ул.\", \"д.\", \"и т.п.\"]\n",
        "\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        char = text[i]\n",
        "        at_start = (i == 0)\n",
        "\n",
        "        # Проверка сокращений\n",
        "        matched_abbr = None\n",
        "        for abbr in abbreviations:\n",
        "            if text[i:i+len(abbr)] == abbr:\n",
        "                matched_abbr = abbr\n",
        "                break\n",
        "        if matched_abbr:\n",
        "            if new_text and not new_text.endswith(\" \"):\n",
        "                new_text += \" \"\n",
        "            new_text += matched_abbr\n",
        "            i += len(matched_abbr)\n",
        "            prev_char = matched_abbr[-1]\n",
        "            continue\n",
        "\n",
        "        # 1) Пробел после знаков препинания (, . ! ?), кроме троеточия в начале\n",
        "        if prev_char in \",.!?\":\n",
        "            if not char.isspace():\n",
        "                new_text += \" \"\n",
        "\n",
        "        # 2) Смена языка (русский - английский)\n",
        "        if prev_char and prev_char.isalpha() and char.isalpha():\n",
        "            if (prev_char.isascii() and not char.isascii()) or (not prev_char.isascii() and char.isascii()):\n",
        "                new_text += \" \"\n",
        "\n",
        "        # 3) Большая буква - начало нового слова\n",
        "        if prev_char and char.isupper() and prev_char.islower():\n",
        "            new_text += \" \"\n",
        "\n",
        "        # 4) Цифры отделяем от букв\n",
        "        if prev_char and ((prev_char.isdigit() and char.isalpha()) or (prev_char.isalpha() and char.isdigit())):\n",
        "            new_text += \" \"\n",
        "\n",
        "        # 5) Скобки и кавычки\n",
        "        opening_quotes = \"([{«'\\\"\"\n",
        "        closing_quotes = \")]}»'\\\"\"\n",
        "\n",
        "        if char in opening_quotes and new_text and not new_text.endswith(\" \"):\n",
        "            new_text += \" \"\n",
        "        elif char in closing_quotes and i+1 < len(text) and not text[i+1].isspace():\n",
        "            new_text += char + \" \"\n",
        "            prev_char = char\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        new_text += char\n",
        "        prev_char = char\n",
        "        i += 1\n",
        "\n",
        "    # 6) Убираем лишние пробелы перед знаками препинания\n",
        "    new_text = re.sub(r\"\\s+([,.!?])\", r\"\\1\", new_text)\n",
        "    # 7) Убираем лишние пробелы в начале и конце\n",
        "    new_text = new_text.strip()\n",
        "\n",
        "    return new_text\n",
        "\n",
        "# Примеры использования\n",
        "text1 = \"онсказал:'Яволк'родилсявСССР\"\n",
        "text2 = \"Яродлсяв2014,этопосле2013года.\"\n",
        "\n",
        "print(insert_spaces(text1))\n",
        "print(insert_spaces(text2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy3\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def is_known_word(word):\n",
        "    \"\"\"\n",
        "    Проверяем знает ли наш анализатор такое слово\n",
        "    \"\"\"\n",
        "    one_letter_words = ['а', 'б', 'в', 'и', 'к', 'о', 'c', 'у', 'я'] # однобуквенные слова\n",
        "    if len(word) == 1 and word not in one_letter_words:\n",
        "        return False\n",
        "    parses = morph.parse(word.lower())\n",
        "    return any(p.is_known for p in parses)\n",
        "\n",
        "def dp_split_longest_word(text, max_word_len=30):\n",
        "    \"\"\"\n",
        "    DP с приоритетом:\n",
        "    1) минимальное количество слов\n",
        "    2) среди разбиений с одинаковым количеством слов — максимально длинные слова\n",
        "    \"\"\"\n",
        "    n = len(text)\n",
        "    dp = [(float('inf'), [], [])] * (n + 1)\n",
        "    dp[0] = (0, [], [])\n",
        "\n",
        "    for i in range(1, n + 1):\n",
        "        best = (float('inf'), [], [])\n",
        "        found_known = False\n",
        "        for j in range(max(0, i - max_word_len), i):\n",
        "            candidate = text[j:i]\n",
        "            if is_known_word(candidate):\n",
        "                found_known = True\n",
        "                prev_num, prev_words, prev_lengths = dp[j]\n",
        "                num_words = prev_num + 1\n",
        "                lengths = prev_lengths + [len(candidate)]\n",
        "                if (num_words < best[0]) or (num_words == best[0] and lengths > best[2]):\n",
        "                    best = (num_words, prev_words + [candidate], lengths)\n",
        "        if found_known:\n",
        "            dp[i] = best\n",
        "        else:\n",
        "            j = i - 1\n",
        "            while j >= 0 and dp[j][0] == float('inf'):\n",
        "                j -= 1\n",
        "            unknown_segment = text[j:i] if j >= 0 else text[:i]\n",
        "            num_words = (dp[j][0] if j >= 0 else 0) + 1\n",
        "            words = (dp[j][1] if j >= 0 else []) + [unknown_segment]\n",
        "            lengths = (dp[j][2] if j >= 0 else []) + [len(unknown_segment)]\n",
        "            dp[i] = (num_words, words, lengths)\n",
        "\n",
        "    return dp[n][1]\n"
      ],
      "metadata": {
        "id": "O8WyjabchZmQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_single_letters(words):\n",
        "    \"\"\"\n",
        "    Объединяет подряд идущие одиночные буквы в одно слово,\n",
        "    кроме 'я'\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    buffer = []\n",
        "\n",
        "    for w in words:\n",
        "        if len(w) == 1 and w != 'я':\n",
        "            buffer.append(w)\n",
        "        else:\n",
        "            if buffer:\n",
        "                result.append(\"\".join(buffer))\n",
        "                buffer = []\n",
        "            result.append(w)\n",
        "\n",
        "    if buffer:  # добавляем оставшиеся в буфере\n",
        "        result.append(\"\".join(buffer))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "mNIPsMqcS3-7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def process_text(text):\n",
        "  \"\"\"\n",
        "    Финальная функция применяющая все шаги алгоритма:\n",
        "    1. Первичное деление по правилам\n",
        "    2. Более умное дробление с дп\n",
        "    3. Конкатенция слишком раздробленных слов (однобуквенных)\n",
        "  \"\"\"\n",
        "\n",
        "  text = insert_spaces(text)\n",
        "\n",
        "  splited = text.split()\n",
        "  new_split = []\n",
        "\n",
        "  for token in splited:\n",
        "    if token[0].isdigit():\n",
        "        new_split.append(token)\n",
        "        continue\n",
        "    if re.match(r\"^[A-Za-z]+$\", token[0]):\n",
        "        new_split.append(token)\n",
        "        continue\n",
        "    start = ''\n",
        "    for i in token:\n",
        "      if i not in string.punctuation:\n",
        "        break\n",
        "      start += i\n",
        "\n",
        "    clean_token = token.strip(string.punctuation)\n",
        "    dp_split = dp_split_longest_word(clean_token)\n",
        "\n",
        "    end = ''\n",
        "    for i in token[::-1]:\n",
        "      if i not in string.punctuation:\n",
        "        break\n",
        "      end = i + end\n",
        "\n",
        "    dp_split = \" \".join(merge_single_letters(dp_split))\n",
        "    dp_split = start + dp_split + end\n",
        "    new_split.append(dp_split)\n",
        "\n",
        "  return \" \".join(new_split)\n",
        "\n"
      ],
      "metadata": {
        "id": "9r3Ary1yWBEJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_test_file(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            row_id, text = line.strip().split(\",\", 1)\n",
        "            rows.append((row_id, text))\n",
        "    return pd.DataFrame(rows, columns=[\"id\", \"text_no_spaces\"])\n",
        "\n",
        "def get_space_positions(original_text, spaced_text):\n",
        "    positions = []\n",
        "    idx = 0\n",
        "    for ch in spaced_text:\n",
        "        if ch == \" \":\n",
        "            positions.append(idx)\n",
        "        else:\n",
        "            idx += 1\n",
        "    return positions\n",
        "\n",
        "\n",
        "def process_file(input_path, output_path):\n",
        "    \"\"\"\n",
        "    Формируем финальный файл с предсказаниями\n",
        "    \"\"\"\n",
        "    df = read_test_file(input_path)\n",
        "\n",
        "    ids = []\n",
        "    texts = []\n",
        "    positions = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        row_id = row[\"id\"]\n",
        "        text = row[\"text_no_spaces\"]\n",
        "\n",
        "        processed_text = process_text(text)\n",
        "\n",
        "        space_positions = get_space_positions(text, processed_text)\n",
        "\n",
        "        ids.append(row_id)\n",
        "        texts.append(processed_text)\n",
        "        positions.append(space_positions)\n",
        "\n",
        "    df = pd.DataFrame({\"predicted_positions\": positions})\n",
        "\n",
        "    df = df.reset_index(drop=False).rename({\"index\": \"id\"}, axis=1)\n",
        "    df.to_csv(output_path)\n",
        "\n",
        "\n",
        "\n",
        "process_file(\"test.txt\", \"submission.csv\")\n"
      ],
      "metadata": {
        "id": "wNaU8UrZdrOC"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}